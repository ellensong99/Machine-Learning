{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A3E1_3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Flip and blur the test set images\n"
      ],
      "metadata": {
        "id": "0JYpIhcLnUoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import mnist \n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "fyg9fKq4fHi-"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resizing(mnist):\n",
        "     train_data = []\n",
        "     for img in mnist:\n",
        "            resized_img = cv2.resize(img, (32, 32))\n",
        "            train_data.append(resized_img)\n",
        "     return train_data\n",
        "\n",
        "def flip_ver(mnist):\n",
        "     train_data = []\n",
        "     for img in mnist:\n",
        "            resized_img = cv2.resize(img, (32, 32))\n",
        "            resized_img = cv2.flip(resized_img, 0)\n",
        "            train_data.append(resized_img)\n",
        "     return train_data\n",
        "\n",
        "def flip_hor(mnist):\n",
        "     train_data = []\n",
        "     for img in mnist:\n",
        "            resized_img = cv2.resize(img, (32, 32))\n",
        "            resized_img = cv2.flip(resized_img, 1)\n",
        "            train_data.append(resized_img)\n",
        "     return train_data\n",
        "newX_train = np.array(resizing(X_train))\n",
        "verX_test = np.array(flip_ver(X_test))\n",
        "horX_test = np.array(flip_hor(X_test))"
      ],
      "metadata": {
        "id": "HQDOCcO8fKE8"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend\n",
        "if keras.backend.image_data_format() == 'channels_first':\n",
        "  newX_train = newX_train.reshape(len(newX_train), 1, 32, 32)\n",
        "  verX_test = verX_test.reshape(len(verX_test), 1, 32, 32)\n",
        "  horX_test = horX_test.reshape(len(horX_test), 1, 32, 32)\n",
        "  input_shape = (1, 32, 32)\n",
        "else:\n",
        "  newX_train = newX_train.reshape(len(newX_train), 32, 32, 1)\n",
        "  verX_test = verX_test.reshape(len(verX_test), 32, 32, 1)\n",
        "  horX_test = horX_test.reshape(len(horX_test), 32, 32, 1)\n",
        "  input_shape = (32, 32, 1)"
      ],
      "metadata": {
        "id": "oYvwLszJfPLp"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "def nor(dataset):\n",
        "  dataset = dataset.astype('float32')\n",
        "  dataset /= 255\n",
        "  return dataset\n",
        "newX_train = nor(newX_train)\n",
        "verX_test = nor(verX_test)\n",
        "horX_test = nor(horX_test)\n",
        "Y_train = keras.utils.np_utils.to_categorical(Y_train, 10)\n",
        "Y_test = keras.utils.np_utils.to_categorical(Y_test, 10)"
      ],
      "metadata": {
        "id": "N4tYjN2FfR2K"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten \n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
        "model.add(Flatten()) \n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MgrD4TSfSw0",
        "outputId": "18bf8e79-647b-42bd-a6eb-4bce42c19835"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_40 (Conv2D)          (None, 32, 32, 64)        640       \n",
            "                                                                 \n",
            " max_pooling2d_25 (MaxPoolin  (None, 16, 16, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_41 (Conv2D)          (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_26 (MaxPoolin  (None, 8, 8, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_42 (Conv2D)          (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " conv2d_43 (Conv2D)          (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " max_pooling2d_27 (MaxPoolin  (None, 4, 4, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_44 (Conv2D)          (None, 4, 4, 512)         1180160   \n",
            "                                                                 \n",
            " conv2d_45 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " max_pooling2d_28 (MaxPoolin  (None, 2, 2, 512)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_46 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " conv2d_47 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " max_pooling2d_29 (MaxPoolin  (None, 1, 1, 512)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 4096)              2101248   \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 512)               2097664   \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,204,682\n",
            "Trainable params: 30,204,682\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "yul3_g4afZyK"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# history = model.fit(newX_train[:6000], Y_train[:6000], batch_size=32, validation_data=(verX_test,Y_test), epochs=10, verbose=1)\n",
        "# model.evaluate(verX_test, Y_test, batch_size=32)[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5Zh-9kMfeu2",
        "outputId": "02ae7024-51df-402c-cc3c-fc2b70737819"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "188/188 [==============================] - 468s 2s/step - loss: 2.0570 - accuracy: 0.2913 - val_loss: 4.1283 - val_accuracy: 0.1900\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 465s 2s/step - loss: 0.6647 - accuracy: 0.7685 - val_loss: 4.7797 - val_accuracy: 0.2714\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 461s 2s/step - loss: 0.2288 - accuracy: 0.9338 - val_loss: 3.4100 - val_accuracy: 0.3175\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 435s 2s/step - loss: 0.1393 - accuracy: 0.9603 - val_loss: 3.6378 - val_accuracy: 0.3225\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 430s 2s/step - loss: 0.0968 - accuracy: 0.9710 - val_loss: 4.5351 - val_accuracy: 0.2511\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 432s 2s/step - loss: 0.0731 - accuracy: 0.9773 - val_loss: 4.7789 - val_accuracy: 0.3490\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 432s 2s/step - loss: 0.0630 - accuracy: 0.9802 - val_loss: 4.0217 - val_accuracy: 0.3306\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 430s 2s/step - loss: 0.0478 - accuracy: 0.9872 - val_loss: 5.3699 - val_accuracy: 0.3153\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 432s 2s/step - loss: 0.0358 - accuracy: 0.9890 - val_loss: 5.1194 - val_accuracy: 0.3343\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 429s 2s/step - loss: 0.0304 - accuracy: 0.9912 - val_loss: 5.6767 - val_accuracy: 0.3249\n",
            "313/313 [==============================] - 60s 191ms/step - loss: 5.6767 - accuracy: 0.3249\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3249000012874603"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### The vertical flip test accuracy is 0.3249, which is greatly reduced compared to previous one.\n"
      ],
      "metadata": {
        "id": "VQNBshiq5zWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(newX_train[:6000], Y_train[:6000], batch_size=32, validation_data=(horX_test,Y_test), epochs=10, verbose=1)\n",
        "model.evaluate(horX_test, Y_test, batch_size=32)[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcTCwuJT5tPX",
        "outputId": "74a45861-d1a7-459f-81c7-5fd37027163a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "188/188 [==============================] - 443s 2s/step - loss: 2.2923 - accuracy: 0.1392 - val_loss: 2.2484 - val_accuracy: 0.2813\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 444s 2s/step - loss: 1.4601 - accuracy: 0.4870 - val_loss: 3.5541 - val_accuracy: 0.2884\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 443s 2s/step - loss: 0.3015 - accuracy: 0.9090 - val_loss: 3.5167 - val_accuracy: 0.3417\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 444s 2s/step - loss: 0.1533 - accuracy: 0.9543 - val_loss: 4.2139 - val_accuracy: 0.3489\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 441s 2s/step - loss: 0.1030 - accuracy: 0.9692 - val_loss: 3.5716 - val_accuracy: 0.4475\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 439s 2s/step - loss: 0.0794 - accuracy: 0.9775 - val_loss: 3.8853 - val_accuracy: 0.3889\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 440s 2s/step - loss: 0.0607 - accuracy: 0.9813 - val_loss: 3.7742 - val_accuracy: 0.3730\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 440s 2s/step - loss: 0.0497 - accuracy: 0.9853 - val_loss: 5.8177 - val_accuracy: 0.3060\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 442s 2s/step - loss: 0.0397 - accuracy: 0.9890 - val_loss: 4.2416 - val_accuracy: 0.3357\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 442s 2s/step - loss: 0.0392 - accuracy: 0.9887 - val_loss: 5.8868 - val_accuracy: 0.3322\n",
            "313/313 [==============================] - 60s 191ms/step - loss: 5.8868 - accuracy: 0.3322\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.33219999074935913"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### The vertical flip test accuracy is 0.3322, which is greatly reduced compared to previous one."
      ],
      "metadata": {
        "id": "mCCexyzsjGZ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add standard Gaussian noise"
      ],
      "metadata": {
        "id": "dInrunkIrJDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import mnist \n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "vvipYnDpxC02"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resizing(mnist):\n",
        "     train_data = []\n",
        "     for img in mnist:\n",
        "            resized_img = cv2.resize(img, (32, 32))\n",
        "            train_data.append(resized_img)\n",
        "     return train_data\n",
        "\n",
        "newX_train = np.array(resizing(X_train))\n",
        "newX_test = np.array(resizing(X_test))"
      ],
      "metadata": {
        "id": "fR6yFV4DxErV"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend\n",
        "if keras.backend.image_data_format() == 'channels_first':\n",
        "  newX_train = newX_train.reshape(len(newX_train), 1, 32, 32)\n",
        "  newX_test = newX_test.reshape(len(newX_test), 1, 32, 32)\n",
        "  input_shape = (1, 32, 32)\n",
        "else:\n",
        "  newX_train = newX_train.reshape(len(newX_train), 32, 32, 1)\n",
        "  newX_test = newX_test.reshape(len(newX_test), 32, 32, 1)\n",
        "  horX_test = horX_test.reshape(len(horX_test), 32, 32, 1)\n",
        "  input_shape = (32, 32, 1)"
      ],
      "metadata": {
        "id": "AVzicXFGxMp2"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "newX_train = newX_train.astype('float32')\n",
        "newX_train /= 255\n",
        "newX_test = newX_test.astype('float32')\n",
        "newX_test /= 255\n",
        "Y_train = keras.utils.np_utils.to_categorical(Y_train, 10)\n",
        "Y_test = keras.utils.np_utils.to_categorical(Y_test, 10)"
      ],
      "metadata": {
        "id": "K-_xJjxhxQhQ"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import GaussianNoise\n",
        "var = [0.01, 0.1, 1]\n",
        "for i in var:\n",
        "  sample = GaussianNoise(i, dtype=tf.float64)\n",
        "  noisey = sample(newX_test,training=True) \n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
        "  model.add(Conv2D(256, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "  model.add(Conv2D(256, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
        "  model.add(Conv2D(512, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "  model.add(Conv2D(512, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
        "  model.add(Conv2D(512, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "  model.add(Conv2D(512, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
        "  model.add(Flatten()) \n",
        "  model.add(Dense(4096, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(4096, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "  sgd = SGD(learning_rate=0.01, decay=1e-3, momentum=0.9, nesterov=True)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "  history = model.fit(newX_train[:6000], Y_train[:6000], batch_size=32, validation_data=(newX_test,Y_test), epochs=10, verbose=1)\n",
        "  acc = model.evaluate(newX_test, Y_test, batch_size=32)[1]\n",
        "  print(\"Test accuracy when variance is \" + i + \"is \" + acc)\n",
        "print(\"Test accuracy when variance is \" + i + \"is \" + acc)"
      ],
      "metadata": {
        "id": "PCjPGyAjqCl5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "outputId": "f20d90fa-86c3-489a-899e-2bc06658d2e2"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "188/188 [==============================] - 454s 2s/step - loss: 2.3006 - accuracy: 0.1075 - val_loss: 2.3000 - val_accuracy: 0.1028\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 447s 2s/step - loss: 2.2759 - accuracy: 0.1885 - val_loss: 2.1143 - val_accuracy: 0.2957\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 443s 2s/step - loss: 1.0821 - accuracy: 0.6157 - val_loss: 0.5441 - val_accuracy: 0.8251\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 445s 2s/step - loss: 0.3144 - accuracy: 0.9072 - val_loss: 0.2282 - val_accuracy: 0.9289\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 445s 2s/step - loss: 0.1580 - accuracy: 0.9517 - val_loss: 0.2303 - val_accuracy: 0.9291\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 442s 2s/step - loss: 0.1138 - accuracy: 0.9662 - val_loss: 0.1257 - val_accuracy: 0.9628\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 444s 2s/step - loss: 0.0746 - accuracy: 0.9787 - val_loss: 0.1072 - val_accuracy: 0.9680\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 443s 2s/step - loss: 0.0551 - accuracy: 0.9828 - val_loss: 0.1228 - val_accuracy: 0.9627\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 440s 2s/step - loss: 0.0429 - accuracy: 0.9853 - val_loss: 0.0958 - val_accuracy: 0.9716\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 442s 2s/step - loss: 0.0346 - accuracy: 0.9897 - val_loss: 0.1167 - val_accuracy: 0.9684\n",
            "313/313 [==============================] - 59s 188ms/step - loss: 0.1167 - accuracy: 0.9684\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-28776c92e627>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test accuracy when variance is \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"is \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"float\") to str"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test accuracy for variance of \" + str(i) + \" is \" + str(acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKoiN3N41ACV",
        "outputId": "0efac70e-ae5d-4c1c-fa13-c1ccc2936137"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy for variance of 0.01 is 0.9684000015258789\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import GaussianNoise\n",
        "var = [0.1, 1]\n",
        "for i in var:\n",
        "  sample = GaussianNoise(i, dtype=tf.float64)\n",
        "  noisey = sample(newX_test,training=True) \n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
        "  model.add(Conv2D(256, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "  model.add(Conv2D(256, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
        "  model.add(Conv2D(512, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "  model.add(Conv2D(512, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
        "  model.add(Conv2D(512, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "  model.add(Conv2D(512, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
        "  model.add(Flatten()) \n",
        "  model.add(Dense(4096, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(4096, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "  sgd = SGD(learning_rate=0.01, decay=1e-3, momentum=0.9, nesterov=True)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "  history = model.fit(newX_train[:6000], Y_train[:6000], batch_size=32, validation_data=(newX_test[:1000],Y_test[:1000]), epochs=10, verbose=1)\n",
        "  acc = model.evaluate(newX_test[:1000], Y_test[:1000], batch_size=32)[1]\n",
        "  print(\"Test accuracy when variance is \" + str(i) + \"is \" + str(acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJ2Ecmwq1TCt",
        "outputId": "102ef3de-885a-4b60-941d-1401e0a17fba"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "188/188 [==============================] - 505s 2s/step - loss: 2.3003 - accuracy: 0.1135 - val_loss: 2.2970 - val_accuracy: 0.1028\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 444s 2s/step - loss: 2.2170 - accuracy: 0.2188 - val_loss: 1.6515 - val_accuracy: 0.4580\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 445s 2s/step - loss: 0.7784 - accuracy: 0.7350 - val_loss: 0.3651 - val_accuracy: 0.8851\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 436s 2s/step - loss: 0.2451 - accuracy: 0.9257 - val_loss: 0.1781 - val_accuracy: 0.9431\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 434s 2s/step - loss: 0.1508 - accuracy: 0.9537 - val_loss: 0.1845 - val_accuracy: 0.9452\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 435s 2s/step - loss: 0.1010 - accuracy: 0.9695 - val_loss: 0.1321 - val_accuracy: 0.9603\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 435s 2s/step - loss: 0.0663 - accuracy: 0.9785 - val_loss: 0.1117 - val_accuracy: 0.9660\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 438s 2s/step - loss: 0.0500 - accuracy: 0.9845 - val_loss: 0.1190 - val_accuracy: 0.9639\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 437s 2s/step - loss: 0.0384 - accuracy: 0.9873 - val_loss: 0.0966 - val_accuracy: 0.9724\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 434s 2s/step - loss: 0.0285 - accuracy: 0.9918 - val_loss: 0.1219 - val_accuracy: 0.9672\n",
            "313/313 [==============================] - 59s 187ms/step - loss: 0.1219 - accuracy: 0.9672\n",
            "Test accuracy when variance is 0.1is 0.967199981212616\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 438s 2s/step - loss: 2.3016 - accuracy: 0.1070 - val_loss: 2.3019 - val_accuracy: 0.0982\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 434s 2s/step - loss: 2.2987 - accuracy: 0.1233 - val_loss: 2.2937 - val_accuracy: 0.1477\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 432s 2s/step - loss: 2.1207 - accuracy: 0.2633 - val_loss: 1.3450 - val_accuracy: 0.5092\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 430s 2s/step - loss: 0.6569 - accuracy: 0.7737 - val_loss: 0.2914 - val_accuracy: 0.9097\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 430s 2s/step - loss: 0.2220 - accuracy: 0.9342 - val_loss: 0.1660 - val_accuracy: 0.9482\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 438s 2s/step - loss: 0.1413 - accuracy: 0.9590 - val_loss: 0.1410 - val_accuracy: 0.9571\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 438s 2s/step - loss: 0.0940 - accuracy: 0.9727 - val_loss: 0.1445 - val_accuracy: 0.9573\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 440s 2s/step - loss: 0.0697 - accuracy: 0.9782 - val_loss: 0.1136 - val_accuracy: 0.9664\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 443s 2s/step - loss: 0.0571 - accuracy: 0.9813 - val_loss: 0.0873 - val_accuracy: 0.9708\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 440s 2s/step - loss: 0.0374 - accuracy: 0.9883 - val_loss: 0.1076 - val_accuracy: 0.9686\n",
            "313/313 [==============================] - 59s 188ms/step - loss: 0.1076 - accuracy: 0.9686\n",
            "Test accuracy when variance is 1is 0.9685999751091003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.layers import GaussianNoise\n",
        "# var = [0.01, 0.1, 1]\n",
        "# for i in var:\n",
        "#   sample = GaussianNoise(i, dtype=tf.float64)\n",
        "#   noisey = sample(newX_test,training=True) \n",
        "#   model = Sequential()\n",
        "#   model.add(Conv2D(64, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "#   model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
        "#   model.add(Conv2D(128, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "#   model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
        "#   model.add(Conv2D(256, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "#   model.add(Conv2D(256, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "#   model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
        "#   model.add(Conv2D(512, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "#   model.add(Conv2D(512, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "#   model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
        "#   model.add(Conv2D(512, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "#   model.add(Conv2D(512, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "#   model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
        "#   model.add(Flatten()) \n",
        "#   model.add(Dense(4096, activation='relu'))\n",
        "#   model.add(Dropout(0.5))\n",
        "#   model.add(Dense(4096, activation='relu'))\n",
        "#   model.add(Dropout(0.5))\n",
        "#   model.add(Dense(10, activation='softmax'))\n",
        "#   sgd = SGD(learning_rate=0.01, decay=1e-3, momentum=0.9, nesterov=True)\n",
        "#   model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "#   history = model.fit(newX_train[:6000], Y_train[:6000], batch_size=32, validation_data=(newX_test[:1000],Y_test[:1000]), epochs=10, verbose=1)\n",
        "#   acc = model.evaluate(newX_test[:1000], Y_test[:1000], batch_size=32)[1]\n",
        "#   print(\"Test accuracy when variance is \" + str(i) + \"is \" + str(acc))"
      ],
      "metadata": {
        "id": "-2d8SIW3geqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Summary\n",
        "\n",
        "1.   Test Accuracy when Gaussian noise of variance 0.01: 0.9684\n",
        "2.   Test Accuracy when Gaussian noise of variance 0.1: 0.9672\n",
        "3.   Test Accuracy when Gaussian noise of variance 1: 0.9686\n",
        "\n",
        "##### Test accuracy decreases as variance of noise increases, considering that noises change the images and make them quite different from orginal images.\n"
      ],
      "metadata": {
        "id": "SJUw-NyVG-R4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://raw.githubusercontent.com/brpy/colab-pdf/master/colab_pdf.py\n",
        "from colab_pdf import colab_pdf\n",
        "colab_pdf('A3E1_3.ipynb')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eudVxMz_SVjU",
        "outputId": "9971faa5-b0ab-453a-fbf0-b0aa906ceefb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-03 07:53:35--  https://raw.githubusercontent.com/brpy/colab-pdf/master/colab_pdf.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1864 (1.8K) [text/plain]\n",
            "Saving to: ‘colab_pdf.py’\n",
            "\n",
            "colab_pdf.py        100%[===================>]   1.82K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-03-03 07:53:35 (18.6 MB/s) - ‘colab_pdf.py’ saved [1864/1864]\n",
            "\n",
            "Mounted at /content/drive/\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "Extracting templates from packages: 100%\n"
          ]
        }
      ]
    }
  ]
}