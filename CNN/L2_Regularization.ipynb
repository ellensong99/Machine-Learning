{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A3E1_4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Part 4 L2 Regularization + Flip and blur the test set images\n"
      ],
      "metadata": {
        "id": "0JYpIhcLnUoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import mnist \n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "fyg9fKq4fHi-"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resizing(mnist):\n",
        "     train_data = []\n",
        "     for img in mnist:\n",
        "            resized_img = cv2.resize(img, (32, 32))\n",
        "            train_data.append(resized_img)\n",
        "     return train_data\n",
        "\n",
        "def flip_ver(mnist):\n",
        "     train_data = []\n",
        "     for img in mnist:\n",
        "            resized_img = cv2.resize(img, (32, 32))\n",
        "            resized_img = cv2.flip(resized_img, 0)\n",
        "            train_data.append(resized_img)\n",
        "     return train_data\n",
        "\n",
        "def flip_hor(mnist):\n",
        "     train_data = []\n",
        "     for img in mnist:\n",
        "            resized_img = cv2.resize(img, (32, 32))\n",
        "            resized_img = cv2.flip(resized_img, 1)\n",
        "            train_data.append(resized_img)\n",
        "     return train_data\n",
        "verX_train = np.array(flip_ver(X_train))\n",
        "horX_train = np.array(flip_hor(X_train))\n",
        "verX_test = np.array(flip_ver(X_test))\n",
        "horX_test = np.array(flip_hor(X_test))"
      ],
      "metadata": {
        "id": "HQDOCcO8fKE8"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend\n",
        "if keras.backend.image_data_format() == 'channels_first':\n",
        "  verX_train = verX_train.reshape(len(verX_train), 1, 32, 32)\n",
        "  verX_test = verX_test.reshape(len(verX_test), 1, 32, 32)\n",
        "  horX_train = horX_train.reshape(len(horX_train), 1, 32, 32)\n",
        "  horX_test = horX_test.reshape(len(horX_test), 1, 32, 32)\n",
        "  input_shape = (1, 32, 32)\n",
        "else:\n",
        "  verX_train = verX_train.reshape(len(verX_train), 32, 32, 1)\n",
        "  verX_test = verX_test.reshape(len(verX_test), 32, 32, 1)\n",
        "  horX_train = horX_train.reshape(len(horX_train), 32, 32, 1)\n",
        "  horX_test = horX_test.reshape(len(horX_test), 32, 32, 1)\n",
        "  input_shape = (32, 32, 1)"
      ],
      "metadata": {
        "id": "oYvwLszJfPLp"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "def nor(dataset):\n",
        "  dataset = dataset.astype('float32')\n",
        "  dataset /= 255\n",
        "  return dataset\n",
        "verX_test = nor(verX_test)\n",
        "horX_test = nor(horX_test)\n",
        "verX_train = nor(verX_train)\n",
        "horX_train = nor(horX_train)\n",
        "Y_train = keras.utils.np_utils.to_categorical(Y_train, 10)\n",
        "Y_test = keras.utils.np_utils.to_categorical(Y_test, 10)"
      ],
      "metadata": {
        "id": "N4tYjN2FfR2K"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten \n",
        "from keras import regularizers\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=input_shape, padding='same', kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', input_shape=input_shape, padding='same', kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', input_shape=input_shape, padding='same', kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', input_shape=input_shape, padding='same', kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', input_shape=input_shape, padding='same', kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', input_shape=input_shape, padding='same', kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', input_shape=input_shape, padding='same', kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', input_shape=input_shape, padding='same', kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
        "model.add(Flatten()) \n",
        "model.add(Dense(4096, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4096, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax', kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MgrD4TSfSw0",
        "outputId": "30297e7a-57db-41a8-f06b-4eb5f7776bc5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_8 (Conv2D)           (None, 32, 32, 64)        640       \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 16, 16, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 8, 8, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 4, 4, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 4, 4, 512)         1180160   \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 2, 2, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 1, 1, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4096)              2101248   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                40970     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,142,858\n",
            "Trainable params: 28,142,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "yul3_g4afZyK"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(verX_train[:6000], Y_train[:6000], batch_size=32, validation_data=(verX_test[:1000],Y_test[:1000]), epochs=10, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "id": "l5Zh-9kMfeu2",
        "outputId": "dd12b01d-f2df-4f81-97d9-fa48db6194c5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "188/188 [==============================] - 247s 1s/step - loss: 8.9239 - accuracy: 0.1593 - val_loss: 8.5978 - val_accuracy: 0.2630\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 248s 1s/step - loss: 8.4418 - accuracy: 0.1522 - val_loss: 8.1964 - val_accuracy: 0.1590\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 249s 1s/step - loss: 7.4932 - accuracy: 0.3493 - val_loss: 6.6459 - val_accuracy: 0.5620\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 247s 1s/step - loss: 5.9375 - accuracy: 0.7962 - val_loss: 5.8181 - val_accuracy: 0.8120\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 247s 1s/step - loss: 5.2266 - accuracy: 0.9257 - val_loss: 5.0553 - val_accuracy: 0.9270\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 246s 1s/step - loss: 4.7989 - accuracy: 0.9547 - val_loss: 4.6755 - val_accuracy: 0.9390\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 246s 1s/step - loss: 4.4463 - accuracy: 0.9657 - val_loss: 4.3356 - val_accuracy: 0.9520\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 247s 1s/step - loss: 4.1205 - accuracy: 0.9728 - val_loss: 4.0051 - val_accuracy: 0.9610\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 247s 1s/step - loss: 3.8161 - accuracy: 0.9807 - val_loss: 3.7733 - val_accuracy: 0.9540\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 247s 1s/step - loss: 3.5438 - accuracy: 0.9840 - val_loss: 3.5043 - val_accuracy: 0.9600\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-0da4e92a2118>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1651\u001b[0m                            for i in tf.nest.flatten(single_data)))\n\u001b[1;32m   1652\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1653\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 1000\n  y sizes: 100\nMake sure all arrays contain the same number of samples."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(verX_test[:1000], Y_test[:1000], batch_size=32)[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrxM82T8I2we",
        "outputId": "367e50b1-2945-430b-aaf7-d008bb44bf69"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 5s 166ms/step - loss: 3.5043 - accuracy: 0.9600\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9599999785423279"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### The vertical flip test accuracy with regularization is 0.96."
      ],
      "metadata": {
        "id": "VQNBshiq5zWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(horX_train[:6000], Y_train[:6000], batch_size=32, validation_data=(horX_test[:1000],Y_test[:1000]), epochs=10, verbose=1)\n",
        "model.evaluate(horX_test[:1000], Y_test[:1000], batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcTCwuJT5tPX",
        "outputId": "1c99bf84-ac7f-4dd0-b184-8097e1da76b3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "188/188 [==============================] - 255s 1s/step - loss: 3.7978 - accuracy: 0.8303 - val_loss: 3.3495 - val_accuracy: 0.9490\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 246s 1s/step - loss: 3.1815 - accuracy: 0.9608 - val_loss: 3.0517 - val_accuracy: 0.9620\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 247s 1s/step - loss: 2.9290 - accuracy: 0.9700 - val_loss: 2.8620 - val_accuracy: 0.9610\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 244s 1s/step - loss: 2.7069 - accuracy: 0.9817 - val_loss: 2.6808 - val_accuracy: 0.9590\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 244s 1s/step - loss: 2.5302 - accuracy: 0.9787 - val_loss: 2.4684 - val_accuracy: 0.9640\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 246s 1s/step - loss: 2.3384 - accuracy: 0.9873 - val_loss: 2.3096 - val_accuracy: 0.9670\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 247s 1s/step - loss: 2.1855 - accuracy: 0.9833 - val_loss: 2.3477 - val_accuracy: 0.9190\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 247s 1s/step - loss: 2.0563 - accuracy: 0.9815 - val_loss: 2.0590 - val_accuracy: 0.9620\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 246s 1s/step - loss: 1.8977 - accuracy: 0.9890 - val_loss: 1.9101 - val_accuracy: 0.9660\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 246s 1s/step - loss: 1.7628 - accuracy: 0.9905 - val_loss: 1.7995 - val_accuracy: 0.9630\n",
            "32/32 [==============================] - 5s 162ms/step - loss: 1.7995 - accuracy: 0.9630\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.7995318174362183, 0.9629999995231628]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### The horizontal flip test accuracy with regularization is 0.9630."
      ],
      "metadata": {
        "id": "daga4986sQUB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add standard Gaussian noise"
      ],
      "metadata": {
        "id": "dInrunkIrJDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import mnist \n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "vvipYnDpxC02"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resizing(mnist):\n",
        "     train_data = []\n",
        "     for img in mnist:\n",
        "            resized_img = cv2.resize(img, (32, 32))\n",
        "            train_data.append(resized_img)\n",
        "     return train_data\n",
        "\n",
        "newX_train = np.array(resizing(X_train))\n",
        "newX_test = np.array(resizing(X_test))"
      ],
      "metadata": {
        "id": "fR6yFV4DxErV"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend\n",
        "if keras.backend.image_data_format() == 'channels_first':\n",
        "  newX_train = newX_train.reshape(len(newX_train), 1, 32, 32)\n",
        "  newX_test = newX_test.reshape(len(newX_test), 1, 32, 32)\n",
        "  input_shape = (1, 32, 32)\n",
        "else:\n",
        "  newX_train = newX_train.reshape(len(newX_train), 32, 32, 1)\n",
        "  newX_test = newX_test.reshape(len(newX_test), 32, 32, 1)\n",
        "  input_shape = (32, 32, 1)"
      ],
      "metadata": {
        "id": "AVzicXFGxMp2"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "newX_train = newX_train.astype('float32')\n",
        "newX_train /= 255\n",
        "newX_test = newX_test.astype('float32')\n",
        "newX_test /= 255\n",
        "Y_train = keras.utils.np_utils.to_categorical(Y_train, 10)\n",
        "Y_test = keras.utils.np_utils.to_categorical(Y_test, 10)"
      ],
      "metadata": {
        "id": "K-_xJjxhxQhQ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import GaussianNoise\n",
        "var = [0.01, 0.1, 1]\n",
        "for i in var:\n",
        "  sample = GaussianNoise(i, dtype=tf.float64)\n",
        "  noisey = sample(newX_test,training=True) \n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
        "  model.add(Conv2D(256, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "  model.add(Conv2D(256, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
        "  model.add(Conv2D(512, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "  model.add(Conv2D(512, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
        "  model.add(Conv2D(512, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "  model.add(Conv2D(512, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides = (2, 2)))\n",
        "  model.add(Flatten()) \n",
        "  model.add(Dense(4096, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(4096, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(10, activation='softmax', kernel_regularizer=regularizers.l2(0.001)))\n",
        "  sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "  history = model.fit(newX_train[:6000], Y_train[:6000], batch_size=32, validation_data=(newX_test[:1000],Y_test[:1000]), epochs=10, verbose=1)\n",
        "  acc = model.evaluate(newX_test[:1000], Y_test[:1000], batch_size=32)[1]\n",
        "  print(\"Test accuracy when variance is \" + str(i) + \" is \" + str(acc))\n"
      ],
      "metadata": {
        "id": "PCjPGyAjqCl5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22d28149-584d-41b6-adeb-25e2dc47808a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "188/188 [==============================] - 278s 1s/step - loss: 7.1589 - accuracy: 0.1122 - val_loss: 6.9753 - val_accuracy: 0.1260\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 271s 1s/step - loss: 6.7670 - accuracy: 0.1900 - val_loss: 6.2825 - val_accuracy: 0.2890\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 272s 1s/step - loss: 5.3112 - accuracy: 0.6085 - val_loss: 4.5182 - val_accuracy: 0.8610\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 272s 1s/step - loss: 4.1948 - accuracy: 0.9173 - val_loss: 4.0191 - val_accuracy: 0.9210\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 274s 1s/step - loss: 3.7826 - accuracy: 0.9520 - val_loss: 3.6751 - val_accuracy: 0.9490\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 276s 1s/step - loss: 3.4707 - accuracy: 0.9702 - val_loss: 3.3926 - val_accuracy: 0.9550\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 278s 1s/step - loss: 3.2086 - accuracy: 0.9748 - val_loss: 3.1632 - val_accuracy: 0.9450\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 276s 1s/step - loss: 2.9680 - accuracy: 0.9825 - val_loss: 2.9406 - val_accuracy: 0.9530\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 278s 1s/step - loss: 2.7434 - accuracy: 0.9850 - val_loss: 2.7422 - val_accuracy: 0.9580\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 274s 1s/step - loss: 2.5369 - accuracy: 0.9885 - val_loss: 2.5512 - val_accuracy: 0.9620\n",
            "32/32 [==============================] - 5s 170ms/step - loss: 2.5512 - accuracy: 0.9620\n",
            "Test accuracy when variance is 0.01 is 0.9620000123977661\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 283s 2s/step - loss: 7.1604 - accuracy: 0.1072 - val_loss: 6.9766 - val_accuracy: 0.1260\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 282s 2s/step - loss: 6.8061 - accuracy: 0.1180 - val_loss: 6.6308 - val_accuracy: 0.1920\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 280s 1s/step - loss: 6.2613 - accuracy: 0.2555 - val_loss: 5.5179 - val_accuracy: 0.4730\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 278s 1s/step - loss: 4.4584 - accuracy: 0.8148 - val_loss: 4.0362 - val_accuracy: 0.9210\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 278s 1s/step - loss: 3.8135 - accuracy: 0.9453 - val_loss: 3.6800 - val_accuracy: 0.9420\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 281s 1s/step - loss: 3.5004 - accuracy: 0.9630 - val_loss: 3.4127 - val_accuracy: 0.9470\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 283s 2s/step - loss: 3.2215 - accuracy: 0.9722 - val_loss: 3.1737 - val_accuracy: 0.9580\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 282s 2s/step - loss: 2.9669 - accuracy: 0.9832 - val_loss: 2.9425 - val_accuracy: 0.9600\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 282s 2s/step - loss: 2.7573 - accuracy: 0.9837 - val_loss: 2.7575 - val_accuracy: 0.9560\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 285s 2s/step - loss: 2.5504 - accuracy: 0.9842 - val_loss: 2.5341 - val_accuracy: 0.9660\n",
            "32/32 [==============================] - 5s 164ms/step - loss: 2.5341 - accuracy: 0.9660\n",
            "Test accuracy when variance is 0.1 is 0.9660000205039978\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 287s 2s/step - loss: 7.1573 - accuracy: 0.1108 - val_loss: 6.9722 - val_accuracy: 0.1260\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 283s 2s/step - loss: 6.7136 - accuracy: 0.2158 - val_loss: 6.2826 - val_accuracy: 0.4130\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 283s 2s/step - loss: 5.1455 - accuracy: 0.6802 - val_loss: 4.5906 - val_accuracy: 0.8180\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 281s 1s/step - loss: 4.1920 - accuracy: 0.9140 - val_loss: 4.1056 - val_accuracy: 0.8900\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 281s 1s/step - loss: 3.7874 - accuracy: 0.9542 - val_loss: 3.6633 - val_accuracy: 0.9450\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 282s 2s/step - loss: 3.4727 - accuracy: 0.9707 - val_loss: 3.3451 - val_accuracy: 0.9660\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 282s 1s/step - loss: 3.2110 - accuracy: 0.9738 - val_loss: 3.1572 - val_accuracy: 0.9520\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 284s 2s/step - loss: 2.9626 - accuracy: 0.9825 - val_loss: 3.0599 - val_accuracy: 0.9360\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 285s 2s/step - loss: 2.7511 - accuracy: 0.9828 - val_loss: 2.7593 - val_accuracy: 0.9590\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 288s 2s/step - loss: 2.5490 - accuracy: 0.9853 - val_loss: 2.5116 - val_accuracy: 0.9710\n",
            "32/32 [==============================] - 5s 162ms/step - loss: 2.5116 - accuracy: 0.9710\n",
            "Test accuracy when variance is 1 is 0.9710000157356262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Summary\n",
        "\n",
        "1.   Test Accuracy when Gaussian noise of variance 0.01: 0.962\n",
        "2.   Test Accuracy when Gaussian noise of variance 0.1: 0.966\n",
        "3.   Test Accuracy when Gaussian noise of variance 1: 0.971\n"
      ],
      "metadata": {
        "id": "xdakEeLfJk9m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Augmentation: Vertical and horizontal flipping to the training and testing data. Gaussian noise of variance 0.01/0.1/1 to all images."
      ],
      "metadata": {
        "id": "3yAbwA31KDmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://raw.githubusercontent.com/brpy/colab-pdf/master/colab_pdf.py\n",
        "from colab_pdf import colab_pdf\n",
        "colab_pdf('A3E1_4.ipynb')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFTiSwOCvNcV",
        "outputId": "9fc6047a-c4d6-43e2-bc4a-dfedf8356031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File ‘colab_pdf.py’ already there; not retrieving.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}